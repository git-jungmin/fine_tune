# fine_tune

# ğŸ§  LoRA Fine-Tuning & Ollama Integration

ì´ í”„ë¡œì íŠ¸ëŠ” **Hugging Face PEFT**ë¥¼ ì´ìš©í•´ LoRA ì–´ëŒ‘í„°ë¥¼ í•™ìŠµì‹œí‚¤ê³ ,  
í•™ìŠµëœ ëª¨ë¸ì„ **Ollama**ì—ì„œ ë¶ˆëŸ¬ì™€ ë¡œì»¬ í™˜ê²½ì—ì„œ ì‹¤í–‰í•˜ëŠ” ê³¼ì •ì„ í¬í•¨í•©ë‹ˆë‹¤.

---

## ğŸ“Œ ê°œìš”

- **ëª©ì **: ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì„ ì§ì ‘ ì¬í•™ìŠµí•˜ì§€ ì•Šê³ ,  
  ê²½ëŸ‰ LoRA íŠœë‹ì„ í†µí•´ íŠ¹ì • ë„ë©”ì¸ ì§€ì‹(UX, êµìœ¡, ê°ì •í˜• ëŒ€í™” ë“±)ì„ ì£¼ì…í•˜ëŠ” ê²ƒ
- **ê²°ê³¼ë¬¼**: `adapter_model.safetensors` í˜•íƒœì˜ LoRA ì–´ëŒ‘í„° íŒŒì¼
- **í™œìš©**: Ollamaì˜ `Modelfile`ì— ì—°ê²°í•´ ìƒˆë¡œìš´ ë§ì¶¤í˜• LLMìœ¼ë¡œ ì‹¤í–‰ ê°€ëŠ¥

---

## âš™ï¸ ê°œë°œ í™˜ê²½

| í•­ëª©        | ë²„ì „ / ë„êµ¬                                                      |
| ----------- | ---------------------------------------------------------------- |
| macOS       | Sonoma / Apple Silicon (M1~M3)                                   |
| Python      | 3.9 ì´ìƒ                                                         |
| pip         | 25.2 (ê°€ìƒí™˜ê²½ ë‚´)                                               |
| ì£¼ìš” íŒ¨í‚¤ì§€ | `transformers`, `peft`, `datasets`, `accelerate`, `bitsandbytes` |
| ëª¨ë¸        | Mistral-7B, Llama 3, Phi 3 ë“± ì§€ì›                               |
| Ollama      | v0.12.3 (Stable)                                                 |

---

## ğŸ§± í”„ë¡œì íŠ¸ êµ¬ì¡°

```bash
fine_tune/
â”œâ”€â”€ venv/                            # Python ê°€ìƒí™˜ê²½
â”œâ”€â”€ dataset.jsonl                    # í•™ìŠµ ë°ì´í„° (prompt-response ìŒ)
â”œâ”€â”€ train_lora.py                    # LoRA í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ lora-ux/                         # í•™ìŠµ ê²°ê³¼ (LoRA ì–´ëŒ‘í„°)
â”‚   â”œâ”€â”€ adapter_model.safetensors
â”‚   â”œâ”€â”€ adapter_config.json
â”‚   â””â”€â”€ metadata.json
â”œâ”€â”€ Modelfile                        # Ollamaìš© ëª¨ë¸ ì •ì˜ íŒŒì¼
â”œâ”€â”€ .gitignore                       # Git ì¶”ì  ì œì™¸ ì„¤ì •
â””â”€â”€ requirements.txt                 # ì˜ì¡´ì„± ê´€ë¦¬ (ì„ íƒ)
```

## ğŸ” í•™ìŠµ ë° ì‹¤í–‰ íë¦„

```mermaid
flowchart TD
    A[dataset.jsonl<br>í•™ìŠµ ë°ì´í„°] --> B[train_lora.py<br>LoRA í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸]
    B --> C[lora-ux/<br>í•™ìŠµ ê²°ê³¼ ì–´ëŒ‘í„°]
    C --> D[Modelfile<br>Ollama ëª¨ë¸ ì •ì˜]
    D --> E[ollama create ux-lora<br>ëª¨ë¸ ë“±ë¡]
    E --> F[ollama run ux-lora<br>ì‹¤í–‰ ë° í…ŒìŠ¤íŠ¸]
```

## âœ… í•™ìŠµ â†’ Ollama ì‹¤í–‰ ìˆœì„œ (ìš”ì•½)

### 1. ê°€ìƒí™˜ê²½ í™œì„±í™”

source venv/bin/activate

### 2. ì˜ì¡´ì„± ì„¤ì¹˜

pip install -r requirements.txt

### 3. LoRA í•™ìŠµ ì‹¤í–‰

python train_lora.py

### 4. Ollama ëª¨ë¸ ì¡°ë¦½

ollama create ux-lora -f Modelfile

### 5. ëª¨ë¸ ì‹¤í–‰ í…ŒìŠ¤íŠ¸

ollama run ux-lora
